
import tldextract
import json



# Mapping of common country code top-level domains (ccTLDs) to countries
COUNTRY_MAPPING = {
    'jo': 'Jordan',
    'qa': 'Qatar',
    'ntt': 'Japan',
    'xn': 'Iran',
    'mil': 'United States Department of Defense',
    'la': 'Laos',
    'tokyo':'Japan',
    'mu':'Mauritius',
    'am': 'Armenia',
    'nu': 'Niue',
    'cc': 'Cocos Islands',
    'il': 'Israel',
    'pk':'Pakistan',
    'lb': 'Lebanon',
    'kw': 'Kuwait',
    'eg': 'Egypt',
    'bh': 'Bahrain',
    'tv': 'Tuvalu',
    'mz': 'Mozambique',
    'cf': 'Central African Republic',
    'cr': 'Costa Rica',
    'hn': 'Honduras',
    'lu': 'Luxembourg',
    'ma': 'Morocco',
    'lt': 'Lithuania',
    'ao': 'Angola',
    'uz': 'Uzbekistan',
    'az': 'Azerbaijan',
    'nz': 'New Zealand',
    'asia': 'asia',
    'us': 'United States',
    'uk': 'United Kingdom' ,
    # 'co.uk': 'United Kingdom',
    'de': 'Germany',
    'sa': 'Saudi Arabia',
    'tn': 'Tunisha',
    'lv': 'Latvia',
    'gq': 'Guinea',
    'ua': 'Ukrain',
    'si': 'Slovenia',
    'su': 'Soviet Union',
    'xn--p1ai': 'Russia',
    'fr': 'France',
    'jp': 'Japan',
    'cn': 'China',
    'in': 'India',
    'br': 'Brazil',
    'au': 'Australia',
    'ca': 'Canada',
    'ru': 'Russia',
    'mx': 'Mexico',
    'za': 'South Africa',
    'kr': 'South Korea',
    'it': 'Italy',
    'es': 'Spain',
    'nl': 'Netherlands',
    'se': 'Sweden',
    'ch': 'Switzerland',
    'at': 'Austria',
    'sg': 'Singapore',
    'ar': 'Argentina',
    'dk': 'Denmark',
    'no': 'Norway',
    'fi': 'Finland',
    'pl': 'Poland',
    'ie': 'Ireland',
    'be': 'Belgium',
    'tr': 'Turkey',
    'com': 'Global',
    'edu': 'Education',
    'org': 'Organization',
    'cz': 'Czech Republic',
    'dz': 'Algeria',
    'eu': 'European Union',
    'int': 'International',
    # 'gov.ae': 'United Arab Emirates',
    'ae': 'United Arab Emirates',
    'ps': 'Palestine',
    'br': 'Brazil',
    # 'org.br': 'Brazil',
    'io': 'British Indian Ocean Territory',
    'bd': 'Bangladesh',
    'gov': 'Government',
    'in': 'India',
    'uk': 'United Kingdom',
    'sk': 'Slovakia',
    'pub': 'Public Domain',
    # 'com.br': 'Brazil',
    # 'go.jp': 'Japan',
    'net': 'Network',
    'tips': 'Tips',
    'gr': 'Greece',
    # 'com.cy': 'Cyprus',
    # 'ac.uk': 'United Kingdom',
    'sk': 'Slovakia',
    'pub': 'Public Domain',
    # 'com.br': 'Brazil',
    # 'go.jp': 'Japan',
    'net': 'Network',
    'tips': 'Tips',
    'gr': 'Greece',
    # 'com.cy': 'Cyprus',
    # 'org.uk': 'United Kingdom',
    'life': 'Life',
    # 'gov.uk': 'United Kingdom',
    'cafe': 'Cafe',
    # 'sch.id': 'Indonesia',
    'solutions': 'Solutions',
    'cat': 'Catalonia',
    # 'edu.ar': 'Argentina',
    'eus': 'Basque Country',
    'cl': 'Chile',
    'gov.co': 'Colombia',
    # 'com.pe': 'Peru',
    # 'edu.co': 'Colombia',
    # 'com.mx': 'Mexico',
    'tk': 'Tokelau',
    'group': 'Group',
    # 'gouv.fr': 'France',
    'jobs': 'Jobs',
    'science': 'Science',
    # 'gov.lk': 'Sri Lanka',
    'info': 'Information',
    'on.ca': 'Canada',
    'qc.ca': 'Quebec, Canada',
    'pro': 'Professional',
    # 'gouv.fr': 'France',
    # 'nic.in': 'India',
    # 'ac.in': 'India',
    'fm': 'Micronesia',
    'tw': 'Taiwan',
    # 'com.tw': 'Taiwan',
    'hu': 'Hungary',
    'co': 'Company',
    # 'ac.id': 'Indonesia',
    # 'go.id': 'Indonesia',
    'app': 'Application',
    'id': 'Indonesia',
    # 'co.id': 'Indonesia',
    # 'lg.jp': 'Japan',
    # 'co.jp': 'Japan',
    # 'veneto.it': 'Italy',
    'media': 'Media',
    'hitachi': 'Hitachi',
    # 'toscana.it': 'Italy',
    # 'gov.it': 'Italy',
    'tech': 'Technology',
    # 'emilia-romagna.it': 'Italy',
    'farm': 'Farm',
    'news': 'News',
    'ai': 'Artificial Intelligence',
    'biz': 'Business',
    # 'ac.kr': 'South Korea',
    # 'co.kr': 'South Korea',
    # 'go.kr': 'South Korea',
    # 're.kr': 'South Korea',
    # 'or.kr': 'South Korea',
    # 'gov.my': 'Malaysia',
    # 'com.my': 'Malaysia',
    # 'edu.my': 'Malaysia',
    'my': 'Malaysia',
    'brussels': 'Brussels',
    'sanofi': 'Sanofi',
    # 'edu.pl': 'Poland',
    # 'gov.pl': 'Poland',
    # 'org.pl': 'Poland',
    # 'com.pl': 'Poland',
    'site': 'Site',
    # 'es.gov.br': 'Brazil',
    # 'sp.gov.br': 'Sao Paulo, Brazil',
    'pt': 'Portugal',
    # 'gov.br': 'Brazil',
    # 'edu.br': 'Brazil',
    # 'leg.br': 'Brazil',
    # 'coop.br': 'Brazil',
    # 'se.gov.br': 'Sergipe, Brazil',
    'consulting': 'Consulting',
    'ro': 'Romania',
    'md': 'Moldova',
    'digital': 'Digital',
    'kz': 'Kazakhstan',
    'me': 'Montenegro',
    'by': 'Belarus',
    'ee': 'Estonia',
    "cy": 'Cyprus',
    "pe": 'Peru',
    "lk": 'Sri Lanka',
    "bn": 'Brunei',
    "th": 'Thailand',
    "sony": 'sony',
    "vn": 'Vietnam'
    # 'com.au': 'Australia',
    # 'go.th': 'Thailand',
    # 'ac.th': 'Thailand',
    # 'co.th': 'Thailand',
    # 'or.th': 'Thailand',
    # 'org.tr': 'Turkey',
    # 'com.tr': 'Turkey',
    # 'edu.tr': 'Turkey'
    # 'gov.tr': 'Turkey',
    # 'com.bn': 'Brunei',
    # 'edu.kz': 'Kazakhstan',
    # 'biz.tr': 'Turkey',
    # 'ac.jp': 'Japan',
    # 'edu.vn': 'Vietnam',
    # 'vn': 'Vietnam',
    # 'com.vn': 'Vietnam',
    # 'gov.vn': 'Vietnam',
    # 'org.vn': 'Vietnam',
    # 'sony': 'Sony',
    # 'or.jp': 'Japan'
    # Add more mappings as needed
}


def get_country_from_url(url):
    extracted = tldextract.extract(url)
    tld = extracted.suffix
    parts = url.split('.')
    tld = parts[-1]

    domain = extracted.domain
    if tld in COUNTRY_MAPPING:
        return COUNTRY_MAPPING[tld]
    else:
        print('{}'.format(tld))
        return ""


def add_niraj_country_to_urls(
        unique_file_path = '../Data/unq_urls.json', 
        country_file_path = '../Data/countries.json', 
        ):
    with open(unique_file_path, 'r') as json_file:
        urls_data = json.load(json_file)

    for entry in urls_data:
        entry['country'] = get_country_from_url(entry['url'])
        entry['domain'] = tldextract.extract(entry['url']).domain

    with open(country_file_path, 'w') as json_file:
        json.dump(urls_data, json_file, indent=4)
    return urls_data

